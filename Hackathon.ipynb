{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "import re\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Data\n",
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum() #checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lang_id'].value_counts() # total number of each obsservation under the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info() #information about the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base models\n",
    "names = ['Logistic Regression','Random Forest', 'Nearest Neighbors', \n",
    "         'Decision Tree','MultinomialNB','Linear SVC', 'XG Boost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers\n",
    "classifiers = [\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', LogisticRegression())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', RandomForestClassifier())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', KNeighborsClassifier())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', DecisionTreeClassifier())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', MultinomialNB())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', LinearSVC())]),\n",
    "        Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', XGBClassifier())])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['lang_id']\n",
    "X = train['text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 10) #Splitting the datat into training nd testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "\n",
    "for name, clf in zip(names, classifiers):    \n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train) #Training the model\n",
    "    \n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)   \n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    models[name] = clf #storing the trained models in the models dictionary    \n",
    "    \n",
    "    results.append([name, run_time.best]) \n",
    "\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regresion\n",
    "lr = models['Logistic Regression']\n",
    "t = test['text']\n",
    "y_pred_lr = lr.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_lr })\n",
    "sub.to_csv('submission_lr2.csv', index = False)\n",
    "\n",
    "#Random forest\n",
    "rf = models['Random Forest']\n",
    "y_pred_rf = rf.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_rf })\n",
    "sub.to_csv('submission_fr.csv', index = False)\n",
    "\n",
    "#Nearest Neighbors\n",
    "nn = models['Nearest Neighbors']\n",
    "y_pred_nn = nn.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_nn })\n",
    "sub.to_csv('submission_nn.csv', index = False)\n",
    "\n",
    "#Decision Tree\n",
    "dt = models['Decision Tree']\n",
    "y_pred_dt = dt.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_dt })\n",
    "sub.to_csv('submission_dt.csv', index = False)\n",
    "\n",
    "#MultinomialNB\n",
    "m = models['MultinomialNB']\n",
    "y_pred_m = m.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_m })\n",
    "sub.to_csv('submission_m.csv', index = False)\n",
    "\n",
    "#Linear SCV\n",
    "l_scv = models['Linear SVC']\n",
    "y_pred_l_scv = l_scv.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_l_scv })\n",
    "sub.to_csv('submission_l_svc.csv', index = False)\n",
    "\n",
    "#XGBoost\n",
    "xg = models['XG Boost']\n",
    "y_pred_xg = xg.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_xg })\n",
    "sub.to_csv('submission_xg.csv', index = False)"
   ]
  },
  {
   "source": [
    "# Hyperparameter Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultinomialNB Hyperparameter tuning\n",
    "tfid = TfidfVectorizer()\n",
    "text = tfid.fit_transform(train['text'])\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(text,y, test_size = 0.2, random_state = 10)\n",
    "params = {'alpha':[1,0.1,0.01,0.001,0.0001,0.00001]}\n",
    "\n",
    "grid_MNB = GridSearchCV(MultinomialNB(), params)\n",
    "grid_MNB.fit(X_train_h, y_train_h)\n",
    "print(grid_MNB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB using the hyperparameter\n",
    "multi = Pipeline([('tfid', TfidfVectorizer()),\n",
    "             ('clf', MultinomialNB(alpha = 0.1))])\n",
    "multi.fit(X_train, y_train)\n",
    "t = test['text']\n",
    "y_pred_m = multi.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_m })\n",
    "sub.to_csv('submission_m.csv', index = False)"
   ]
  },
  {
   "source": [
    "## Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic\n",
    "tfid = TfidfVectorizer()\n",
    "text = tfid.fit_transform(df_train['text'])\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(text,y, test_size = 0.2, random_state = 10)\n",
    "n_estimators = [10, 100, 1000, 2000]\n",
    "max_depth = [None, 5, 10, 20]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=rf, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=2,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train_h, y_train_h)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Pipeline([('tfid', TfidfVectorizer()),\n",
    "             ('clf', RandomForestClassifier(n_estimators = 2000, max_depth = None))])\n",
    "rf.fit(X_train, y_train)\n",
    "t = test['text']\n",
    "y_pred_m = rf.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_m })\n",
    "sub.to_csv('submission_rf2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}